To do
-----

At the moment we're just printing out the list of matching URLs, we're not
actually downloading anything. Will need to handle this; maybe static link
against libcurl? We'll need to make sure we can handle http, https, ftp and
file protocols as a minimum.

We need a way to keep track of what's been downloaded, so that we can avoid
downloading it again unnecessarily. The simplest way I can think of for this
is to keep a subversion-style cache dir containing an exact copy of everything
that's been downloaded so far. We look in there first before downloading
anything; provide command line options to flush it out; and so on. Another
option would be to store a manifest file for each download, listing out its
contents (and their hashes?). It would be good to see how well git's object
model matches this problem too.

It probably won't be long before we need compound expressions for conditions:
  
  os "win" and bits "64"
  os "win" or bits "64"
  os not "win"

We should try to keep the set of supported operations as small as possible
while remaining useful. We don't want to encourage people to write hideously
complicated conditions. But at the same time, we don't want users to have to
nest stuff really deeply and/or copy 'n' paste lots of stuff in order to get
the deps they need.

It'll probably be easier to support this if I use a proper flex/bison parser
instead of my custom horrible handwritten one...

It might also be a good idea to switch to dynamic allocation for the variable
lists, simply because sooner or later someone is bound to hit those limits.

We'll need a way to configure, per-project, where dependencies get stored. We
should be able to sue this to automatically figure out a local filename for
each dependency. The things we'll want to configure are:
- Whether we unzip dependencies into the same location, or a separate location.
  If we use separate locations for each dep url, this will make it easier to
  upgrade individual dependencies but will add complication to build scripts.
  Maybe we could keep a list of the files added by each dependency, so that we
  could uninstall exactly? --> Actually that would be good because we can flag
  an error if two dependencies install the same file into the same location.
- Where to store the unzipped dependencies.
- Which folder to use as temporary storage while downloading and unzipping.


